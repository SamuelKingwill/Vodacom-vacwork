{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Logistic regression with IVMax feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "#import os.path\n",
    "import rpy2\n",
    "import scorecardpy as sc\n",
    "from scorecardpy import info_value \n",
    "import seaborn as seabornInstance \n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import RFE, RFECV, mutual_info_classif, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier as RFE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import descartes\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to set\n",
    "\n",
    "These parameters can be changed to affect feature selection and thus the accuracy of the model. They are at the beginning of the notebook to simplify the experimental process to identify optimal feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN = 1 to drop NaN values in dataframe, else NaN = 0\n",
    "NaN = 1\n",
    "\n",
    "# correlated = 1 to drop correlated features in dataframe, else correlated = 0\n",
    "correlated = 1\n",
    "\n",
    "# correlation lower bound to drop features\n",
    "corr_bound = 0.9\n",
    "\n",
    "# minimum difference in IV to drop feature based on correlation bound\n",
    "iv_diff = 0.1 #Feat_sum.loc[:,\"Total_IV\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in, cleaning, and selecting training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = os.path.expanduser( \"~/Documents/Vodacom/data/df_raw_final.pkl\" )\n",
    "\n",
    "df = pd.read_pickle(f)\n",
    "#df = pd.read_pickle('/home/samuel/Documents/Vacation work/env/df_raw_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframe after dropping all values with NaN\n",
    "dfclean = df.dropna( subset = ['target_label'] )\n",
    "\n",
    "#replace all strings \"yes\", \"no\", \"maybe\" with integers 0, 1, 2 \n",
    "dfclean = dfclean.replace( to_replace = \"yes\", value = 1 )\n",
    "dfclean = dfclean.replace( to_replace = \"no\", value = 0 )\n",
    "dfclean = dfclean.replace( to_replace = \"maybe\", value = 2 )\n",
    "\n",
    "# remove all rows with target_label = 2 (\"maybe\") as the model is built for binary logistic regression\n",
    "dfclean = dfclean[ dfclean.target_label != 2 ]\n",
    "\n",
    "# remove all columns that are targets \n",
    "for feature in dfclean :\n",
    "    \n",
    "    if (dfclean[feature].isna().sum() > 100) :\n",
    "#         print(feature)\n",
    "        dfclean = dfclean.drop( columns = feature )\n",
    "        \n",
    "# remove column geometry due to string error with conversion\n",
    "dfclean_nogeo = dfclean.drop( columns = \"geometry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column 'geometry' in dataframe causes unwanted errors.\n",
    "Initialize new dataframe without the 'geometry' column.\n",
    "Assumption that the 'geometry' column causes more issues than has relevance for model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add randomized feature\n",
    "\n",
    "# dfclean_nogeo['randfeature'] = np.random.normal(size = dfclean_nogeo.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data\n",
    "\n",
    "dfclean_nogeo, df_test = train_test_split(dfclean_nogeo, test_size=0.3, random_state = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split before binning to avoid bias in setting bins according to testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying feature types\n",
    "\n",
    "This section runs through all features in dfclean_nogeo in a for loop.\n",
    "If the feature is a float or an integer, we check whether it is a code. If all instances in a feature are numeric and have the same length (ie cellphone numbers all have 10 digits) it is denoted as a code. This is done as follows:\n",
    "\n",
    "The feature values are converted to a list, each value is converted to a string, the length of that string is added to a seperate list. That list is shortened to a set of its unique values. If all the values of the feature are the same length the length of that set is 1 and the feature is noted as a CODE. \n",
    "\n",
    "Features that are 'objects' or noted as a Code are saved as catagorical in a dictionary called Feat_typ, else they are saved as numeric. List of catagorical features and numeric features are both saved seperately and enumerated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Feat_typ = {}\n",
    "Num_typ = {}\n",
    "\n",
    "num_list = []\n",
    "cat_list = []\n",
    "index_list = []\n",
    "\n",
    "j = 1\n",
    "\n",
    "# for loop to identify feature types\n",
    "\n",
    "for i, feature in enumerate( dfclean_nogeo ):\n",
    "    \n",
    "    if ( dfclean_nogeo[ feature ].dtype == 'float64' or dfclean_nogeo[ feature ].dtype == 'int64'):\n",
    "        \n",
    "        value_list = dfclean_nogeo[feature].values\n",
    "        length_values_list = []\n",
    "        \n",
    "# for loop identifying if all items in a given feature have the same number of characters\n",
    "# if they do, identify feature as a category\n",
    "        \n",
    "        for item in value_list:\n",
    "            \n",
    "            length_values_list.append( len( str( item ) ) )\n",
    "\n",
    "# CODE = true if number of characters in values of all features are the same            \n",
    "            \n",
    "        CODE = ( len( set( length_values_list ) ) == 1)\n",
    "        \n",
    "    if (dfclean_nogeo[feature].dtype == 'object' or CODE):     \n",
    "\n",
    "        Feat_typ[feature] = [i,\"cat\"]\n",
    "        index_list.append(feature)\n",
    "        if (feature != 'target_label') :\n",
    "            \n",
    "            cat_list.append(feature)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        Feat_typ[feature] = [i, \"num\"]\n",
    "        Num_typ[feature] = [j, \"num\"]\n",
    "        num_list.append(feature)\n",
    "        index_list.append(feature)\n",
    "        j = j + 1\n",
    "    \n",
    "    # adding the 'target_label' column to num_list    \n",
    "    \n",
    "    if feature == \"target_label\":\n",
    "\n",
    "        num_list.append( feature )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On investigation of this dataset, we decided not to use categorical feature for the model and dropped them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all columns that are targets or categories\n",
    "\n",
    "dfclean_nogeo = dfclean_nogeo.drop( columns = cat_list )\n",
    "\n",
    "df_test = df_test.drop( columns = cat_list )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning and IV calculation\n",
    "\n",
    "##### smbinning using R\n",
    "\n",
    "\n",
    "Features are binned to improve model accuracy. After testing, smbinning proved to produce better IV values indicating better bins. smbinning is only written for R as Conditional Inference Trees dont seem to be possible in python yet. This section initially uses the package rpy2 to swap to R and perfrom the smbinning and return a list of the bins. The smbinning function cannot bin some of the features so only those features which are binned correctly are returned. We create a dictionary of these features and their respective cuts for binning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activates the use of R in the Jupyter Notebook\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Brute force fix for kernel dying on Mac, Error15\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i dfclean_nogeo -o cuts \n",
    "\n",
    "library(smbinning)\n",
    "library(foreach)\n",
    "library(doParallel)\n",
    "\n",
    "\n",
    "comb <- function(...){\n",
    "    mapply('cbind', ..., SIMPLIFY = FALSE)\n",
    "}\n",
    "\n",
    "no_cores <- detectCores()\n",
    "registerDoParallel(cores = 4)\n",
    "\n",
    "numg_list = c()\n",
    "cutsgood = c()\n",
    "\n",
    "Features <- names(dfclean_nogeo)[1:ncol(dfclean_nogeo)]\n",
    "\n",
    "i = 1\n",
    "j = 1\n",
    "\n",
    "ptime <- system.time({\n",
    "\n",
    " cuts = foreach( col = Features, .combine = comb, .packages = 'smbinning')  %dopar%  {\n",
    "\n",
    "    sbin = smbinning( dfclean_nogeo, 'target_label', col )\n",
    "            \n",
    "       if ( !is.na( sbin[ 'bands' ] ) ) {\n",
    "        \n",
    "            cutsgood[[i]] <- sbin$bands[ -length( sbin$bands ) ]\n",
    "            numg_list[i] = col\n",
    "            i = i + 1\n",
    "           \n",
    "        } \n",
    "     \n",
    "        # adding target_label to numg_list\n",
    "        if ( col == \"target_label\" ) {\n",
    "\n",
    "            numg_list[i] = col\n",
    "\n",
    "        }\n",
    "     \n",
    "     return(list(numg_list, cutsgood))\n",
    "     \n",
    "    }\n",
    "    \n",
    "})[3]\n",
    "print(paste(\"Time taken for smbinning =\", ptime, \"seconds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the R objects to a usable python dictionary\n",
    "\n",
    "# create a list for numg_list from an R vector\n",
    "cuts = list(cuts)\n",
    "\n",
    "# creating dictionary of value cutsgood\n",
    "cutsg_dic = dict( zip( cuts[0], cuts[1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WOE binning and IV calculation\n",
    "\n",
    "The woebin function from the scorecardpy package creates IV tables for all numerical features in dataframe. We use smbinning's cut values for the bins for all numerical features within cutsg_dic, all other numerical features for which smbinning failed have bins cut by the woebin function. \n",
    "This is due to the assumption that smbinning's cut values for the bins will yielf a maximized IV while, woebinning's cut values will not be maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight of evidence (WOE) binning and information values calculation of all numerical features\n",
    "\n",
    "num_iv = sc.woebin( dfclean_nogeo.loc[ :, num_list ],\n",
    "                   y = \"target_label\", breaks_list = cutsg_dic, positive = 0, bin_num_limit = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # produce the plots of count distribution and bad probability for each bin for all features\n",
    "# sc.woebin_plot(num_iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of a new Dataframe called feature summary which includees each feature, \n",
    "# the number of unique and NaN values it has, and its IV\n",
    "\n",
    "Feat_sum = pd.DataFrame( dfclean_nogeo.dtypes )\n",
    "\n",
    "for feature in dfclean_nogeo:\n",
    "    \n",
    "    Feat_sum.loc[ feature,\"Unique\" ] = dfclean_nogeo[ feature ].nunique()\n",
    "    Feat_sum.loc[ feature, \"NaNs\" ] = dfclean_nogeo[ feature ].isna().sum()\n",
    "    \n",
    "# adding iv values of numerical features to summary dataframe\n",
    "\n",
    "for feature in dfclean_nogeo.loc[ :, num_list ]:\n",
    "    \n",
    "    if ( feature != 'target_label' ) :\n",
    "        \n",
    "        Feat_sum.loc[ feature,'Total_IV' ] = num_iv[ feature ].total_iv[ 1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation and NaN removal\n",
    "\n",
    "If selected above, features which are highly correlated and which contain NaN values are removed. \n",
    "\n",
    "The threshold for removal based on correlation is set in the second block of the notebook. If two features are correlated above the threshold, the IV values of the features are check. the feature with the lowest IV value is removed. If the IV values are within the IV threshold set above, the features are added to a \"check_list\" and are not removed. Someone with domain experience can look at the pairs of features in the check list and remove the one they would prefer manually if so desired. This is done before woe transformation to save time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating correlation matrix\n",
    "cor = dfclean_nogeo.corr()\n",
    "\n",
    "# # Vsualization of feature correlation:\n",
    "# cor.style.background_gradient(cmap = 'coolwarm')\n",
    "\n",
    "# adding IV values to the correlation matrix\n",
    "cor = cor.join(Feat_sum.Total_IV, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_feat = []\n",
    "check_feat = []\n",
    "\n",
    "for feature, correl in cor.iteritems():\n",
    "    \n",
    "    #for each feature\n",
    "    for i in np.arange(len(correl.values)):\n",
    "    \n",
    "    # run through each row of cor\n",
    "        \n",
    "        if (abs(correl[i]) > corr_bound and correl.index[i] != feature and feature != \"Total_IV\"):\n",
    "    #if the correlation is high and less than one and ignore total IV\n",
    "            \n",
    "            if (cor.loc[correl.index[i], \"Total_IV\"] - cor.loc[feature, \"Total_IV\"] > iv_diff):\n",
    "    #if the IV of the row feature is more than 0.1 greater than the IV of the column feature, \n",
    "    #add the column to the remove list\n",
    "#                 print(\"row \",correl.index[i],\"   is bigger than column     \", feature)\n",
    "                rem_feat.append(feature)\n",
    "            \n",
    "            elif(cor.loc[correl.index[i], \"Total_IV\"] - cor.loc[feature, \"Total_IV\"] > 0):\n",
    "    #if the features have very similar IVs, add them to the check list\n",
    "                check_feat.append([feature, correl.index[i]])\n",
    "\n",
    "rem_feat = list(dict.fromkeys(rem_feat))     #original order\n",
    "\n",
    "#List of features to check:\n",
    "#check_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows containing NaN values \n",
    "if (NaN == 1):\n",
    "    \n",
    "    df_final_noNaN = dfclean_nogeo.dropna()\n",
    "    df_test = df_test.dropna()\n",
    "    \n",
    "else:\n",
    "        \n",
    "    df_final_noNaN = dfclean_nogeo\n",
    "    \n",
    "# drop columns based off of correlation comparison\n",
    "if (correlated == 1) :\n",
    "    \n",
    "    df_final_noNaN = df_final_noNaN.drop(columns = rem_feat)\n",
    "    df_test = df_test.drop(columns = rem_feat)\n",
    "    \n",
    "    \n",
    "# It makes a difference here that we drop na before correlated, but the effect is negligable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WOE transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming training data table to WOE values\n",
    "\n",
    "df_final = sc.woebin_ply(df_final_noNaN, num_iv)\n",
    "\n",
    "# transforming test data to WOE values\n",
    "\n",
    "df_test_final = sc.woebin_ply(df_test, num_iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection using IVMax\n",
    "\n",
    "\n",
    "Features are ordered in Feat_sum in decreasing order of their IV. There is some test manipulation so that feature names match after the woe transformation. \n",
    "\n",
    "The feature with the highest IV is selected and the model is run. The next feature is selected and the model is run again. If the accuracy improves, the feature is kept on the list of features to be used and the next feature is checked. If feature does not improve model accuracy it is skipped. The for loop runs throug all the features in Feat_sum so the model is run many times but it is very fast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feat in enumerate(Feat_sum.iterrows()):\n",
    "    Feat_sum = Feat_sum.rename(index = {feat[0]: feat[0] + \"_woe\"})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feat_sum = Feat_sum.loc[df_final.columns]   #This simulates the corelation and NaN feature drop\n",
    "Feat_sum = Feat_sum.sort_values(\"Total_IV\", ascending = False)\n",
    "Feat_sum.drop(Feat_sum.tail(1).index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_feat_acc_iv = []\n",
    "best_feat = []\n",
    "score2 = 0\n",
    "nom_feat = 0\n",
    "for no_feat in np.arange(len(Feat_sum)):\n",
    "    \n",
    "    new_feat = list(Feat_sum[no_feat:no_feat+1].index)\n",
    "    used_feat = list(best_feat)\n",
    "#     print(\"new = \", new_feat)\n",
    "    used_feat.append(new_feat[0])\n",
    "#     print(\"used = \", used_feat)\n",
    "    X_train_iv = df_final.loc[:,used_feat]\n",
    "    y_train_iv = pd.DataFrame(df_final.target_label)\n",
    "\n",
    "    X_test_iv = df_test_final.loc[:,used_feat]\n",
    "    y_test_iv = pd.DataFrame(df_test_final.target_label)\n",
    "    \n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train_iv, y_train_iv)\n",
    "    y_pred_iv = logreg.predict(X_test_iv)\n",
    "    score1 = logreg.score(X_test_iv, y_test_iv)\n",
    "#     print(score1)\n",
    "    if (score1 > score2) :\n",
    "        score2 = score1\n",
    "        nom_feat = nom_feat + 1\n",
    "        best_feat.append(new_feat[0])\n",
    "        no_feat_acc_iv.append([score2, nom_feat, used_feat])\n",
    "#     print(\"best = \", best_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model accuracy = \", max(no_feat_acc_iv)[0],\n",
    "     \"\\nNumber of features = \", max(no_feat_acc_iv)[1],\n",
    "     \"\\n\\nFeature selected = \", max(no_feat_acc_iv)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTIONS\n",
    "\n",
    "Predictions for all 103576 EAs using the model trained on the original training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features selected, 2 different lists as feature names change after woe transformation\n",
    "used_feat_woe = max(no_feat_acc_iv)[2]\n",
    "used_feat = [feature.replace('_woe', '') for feature in used_feat_woe]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing the database to only those features needed, saves 50 seconds\n",
    "X_pred_iv = df.loc[:,used_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming data into woe values\n",
    "X_pred_iv_woe = sc.woebin_ply(X_pred_iv, num_iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "X_train_iv = df_final.loc[:,used_feat_woe]\n",
    "y_train_iv = pd.DataFrame(df_final.target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_iv_woe = X_pred_iv_woe.reindex(sorted(X_pred_iv_woe.columns), axis=1)\n",
    "X_train_iv = X_train_iv.reindex(sorted(X_train_iv.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver = \"lbfgs\")\n",
    "logreg.fit(X_train_iv, y_train_iv)\n",
    "\n",
    "# Making predictions\n",
    "\n",
    "y_pred_iv = logreg.predict_proba(X_pred_iv_woe)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = pd.DataFrame(df.geometry)\n",
    "map_df['Fibre_prediction'] = y_pred_iv\n",
    "map_df['Province'] = df.PR_NAME\n",
    "# ma = map_df[map_df.target_level == 0]\n",
    "mapp = geopandas.GeoDataFrame(map_df)\n",
    "# ma\n",
    "mapp.plot(column = 'Fibre_prediction', cmap = 'inferno', scheme = 'Natural_Breaks',\n",
    "             legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wc = map_df.loc[map_df.Province == 'Western Cape']\n",
    "mapp_wc = geopandas.GeoDataFrame(df_wc)\n",
    "\n",
    "mapp_wc.plot(column = 'Fibre_prediction', cmap = 'inferno', scheme = 'Natural_Breaks',\n",
    "             legend = True)\n",
    "\n",
    "print('Number of yes values: ', df_wc.Fibre_prediction.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df['MN'] = df.MN_NAME\n",
    "#map_df.MN.unique()\n",
    "df_mn = map_df.loc[map_df.MN == 'City of Cape Town']\n",
    "mapp_mn = geopandas.GeoDataFrame(df_mn)\n",
    "\n",
    "mapp_mn.plot(column = 'Fibre_prediction', cmap = 'inferno', scheme = 'Natural_Breaks',\n",
    "             legend = True)\n",
    "\n",
    "print('Number of yes values: ', df_mn.Fibre_prediction.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gau = map_df.loc[map_df.Province == 'Gauteng']\n",
    "mapp_gau = geopandas.GeoDataFrame(df_gau)\n",
    "mapp_gau.plot(column = 'Fibre_prediction', cmap = 'inferno', scheme = 'Natural_Breaks',\n",
    "             legend = True)\n",
    "print('Number of yes values: ', df_gau.Fibre_prediction.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kzn = map_df.loc[map_df.Province == 'KwaZulu-Natal']\n",
    "mapp_kzn = geopandas.GeoDataFrame(df_kzn)\n",
    "mapp_kzn.plot(column = 'Fibre_prediction', cmap = 'inferno', scheme = 'Natural_Breaks',\n",
    "             legend = True)\n",
    "print('Number of yes values: ', df_kzn.Fibre_prediction.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nw = map_df.loc[map_df.Province == 'North West']\n",
    "mapp_nw = geopandas.GeoDataFrame(df_nw)\n",
    "mapp_nw.plot(column = 'Fibre_prediction', cmap = 'inferno', scheme = 'Natural_Breaks',\n",
    "             legend = True)\n",
    "print('Number of yes values: ', df_nw.Fibre_prediction.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fs = map_df.loc[map_df.Province == 'Free State']\n",
    "mapp_fs = geopandas.GeoDataFrame(df_fs)\n",
    "mapp_fs.plot(column = 'Fibre_prediction', cmap = 'inferno', scheme = 'Natural_Breaks',\n",
    "             legend = True)\n",
    "print('Number of yes values: ', df_fs.Fibre_prediction.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ec = map_df.loc[map_df.Province == 'Eastern Cape']\n",
    "mapp_ec = geopandas.GeoDataFrame(df_ec)\n",
    "mapp_ec.plot(column = 'Fibre_prediction', cmap = 'inferno', scheme = 'Natural_Breaks',\n",
    "             legend = True)\n",
    "print('Number of yes values: ', df_ec.Fibre_prediction.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nc = map_df.loc[map_df.Province == 'Northern Cape']\n",
    "mapp_nc = geopandas.GeoDataFrame(df_nc)\n",
    "mapp_nc.plot(column = 'Fibre_prediction', cmap = 'inferno', scheme = 'Natural_Breaks',\n",
    "             legend = True)\n",
    "print('Number of yes values: ', df_nc.Fibre_prediction.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lim = map_df.loc[map_df.Province == 'Limpopo']\n",
    "mapp_lim = geopandas.GeoDataFrame(df_lim)\n",
    "mapp_lim.plot(column = 'Fibre_prediction', cmap = 'inferno', scheme = 'Natural_Breaks',\n",
    "             legend = True)\n",
    "print('Number of yes values: ', df_lim.Fibre_prediction.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mp = map_df.loc[map_df.Province == 'Mpumalanga']\n",
    "mapp_mp = geopandas.GeoDataFrame(df_mp)\n",
    "mapp_mp.plot(column = 'Fibre_prediction', cmap = 'inferno', scheme = 'Natural_Breaks',\n",
    "             legend = True)\n",
    "print('Number of yes values: ', df_mp.Fibre_prediction.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
